# Flash attention animation

I was trying to exactly understand how Flash attention operates.

This was the image from the [flash attention Github page](https://github.com/Dao-AILab/flash-attention/).

![flash-attention-reference](flashattn_banner.jpg)

Here is a comparison between what I think is default implementation of attention

![normal-attention-reference](normal-attention.gif)

and the implementation of flash attention

![flash-attention](flash-attention.gif)

I will comment more when after I confirm correctness.

The animation was done manually on MacOS Keynote.
